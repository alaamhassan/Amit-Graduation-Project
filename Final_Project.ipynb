{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Needed Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import threading\n",
    "from IPython.display import Audio\n",
    "import pyttsx3\n",
    "import speech_recognition as sr\n",
    "from playsound import playsound\n",
    "import requests\n",
    "import io\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable working on gpu\n",
    "os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=gpu,floatX=float32\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YoloV7 With AudioFeedBack:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return the detected_object_text as AudioFeedBack\n",
    "def playing_audio():\n",
    "    global out_text\n",
    "    global current_text\n",
    "    if (len(out_text)>0) : #and(current_text!=out_text)\n",
    "        last_text=out_text \n",
    "        engine =pyttsx3.init()\n",
    "        engine.say(out_text)\n",
    "        engine.runAndWait()\n",
    "        if engine._inLoop:\n",
    "            engine.endLoop()\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: the object detection Part (the part which run the yolov7) was written from https://github.com/HimanchalChandra/Object-Detection-with-Voice-Feedback-YOLO-v3-and-gTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that detected the objects in the frame,\n",
    "#write bounding boxes and labels on the frame\n",
    "#then return the modified frame.\n",
    "#it's also call the thread of the playing_audio function to \n",
    "#output the detected_object_text as AudioFeedBack\n",
    "def video_stream_with_objectDetection(frame,frame_count):\n",
    "    global text\n",
    "    global texts\n",
    "    global audio_text\n",
    "    global Labels\n",
    "    global COLORS\n",
    "    global network\n",
    "    global layer_names\n",
    "    global current_text\n",
    "    global out_text\n",
    "    global detected_objects \n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "\n",
    "    if (frame_count%100==0):\n",
    "        if(current_text in detected_objects):\n",
    "            detected_objects=[]\n",
    "            if(current_text==out_text):\n",
    "                detected_objects.append(current_text)  \n",
    "\n",
    "    #get the frame dimension\n",
    "    (H,W) =frame.shape[:2]\n",
    "\n",
    "    # convert the frame to blob to give it to the network\n",
    "    blob =cv2.dnn.blobFromImage(frame, 1/255.0, (416,416), crop=False, swapRB=True)\n",
    "\n",
    "    network.setInput(blob)\n",
    "    output_layers=network.forward(layer_names)\n",
    "\n",
    "    # getting the output from the network\n",
    "\n",
    "    boxes =[]\n",
    "    confidences=[]\n",
    "    classIDs=[]\n",
    "    centers=[]\n",
    "\n",
    "    for output in output_layers:\n",
    "        for detection in output:\n",
    "            #take the oneHotEncode vector that represent the label scores\n",
    "            scores =detection[5:]\n",
    "            # taking the index of the label with the highest score\n",
    "            classID =np.argmax(scores)\n",
    "            #get the highest confidence \n",
    "            confidence =scores[classID]\n",
    "\n",
    "            #only take into consideration confidence higher than 0.6\n",
    "            if (confidence >= 0.5):\n",
    "                #getting x,y(bounding box centers) and w,h (width and high)\n",
    "                box=detection[0:4]*np.array([W,H,W,H])\n",
    "                (CenterX,CenterY,w,h) =box.astype(\"int\")\n",
    "\n",
    "                #getting the most bottom left of the box\n",
    "                x=int(CenterX-(w/2))\n",
    "                y=int(CenterY-(h/2))\n",
    "\n",
    "                #append all the results\n",
    "                boxes.append([x,y,int(w),int(h)])\n",
    "                confidences.append(float(confidence))\n",
    "                classIDs.append(classID)\n",
    "                centers.append((CenterY,CenterY))\n",
    "\n",
    "        # removal of overlapping boxes\n",
    "        idxs =cv2.dnn.NMSBoxes(boxes, confidences,0.5,0.3)\n",
    "\n",
    "        #loop ovar detecion\n",
    "    if (len(idxs) >0):\n",
    "        #loop over deteciton\n",
    "        for i in idxs.flatten():\n",
    "            #extract x,y(bottom left point) and w,h (width and high)\n",
    "            (x,y) = (boxes[i][0], boxes[i][1])\n",
    "            (w,h) = (boxes[i][2], boxes[i][2])\n",
    "\n",
    "            # draw the boxes and label on the frame\n",
    "            color =[int(c) for c in COLORS[classIDs[i]]]\n",
    "            \n",
    "            # draw the box\n",
    "            cv2.rectangle(frame, (x,y), (x+w,y+h),color,2)\n",
    "            # write the label\n",
    "            text =\"{}: {:.4f}\".format(Labels[classIDs[i]], confidences[i])\n",
    "            cv2.putText(frame, text, (x,y-5),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,1,color,2)\n",
    "\n",
    "            detected =[]\n",
    "\n",
    "            if frame_count%2 ==0:\n",
    "                current_label =Labels[classIDs[i]]       \n",
    "                #if(current_label not in detected): \n",
    "                    #find x,y centers of the current detected box\n",
    "                x,y =centers[i][0],centers[i][1]\n",
    "                text=\"\"           \n",
    "                if (x<=(W/3)):\n",
    "                    text =\"left \"\n",
    "                elif(x<=((W/3)*2)):\n",
    "                    text =\"center \"\n",
    "                else:\n",
    "                    text =\"right \"\n",
    "\n",
    "                if (y<=(H/3)):\n",
    "                    text =\"top \"+text\n",
    "                elif(y<=((H/3)*2)):\n",
    "                    text =\"mid \"+text\n",
    "                else:\n",
    "                    text =\"bottom \"+text\n",
    "\n",
    "                out_text =text+\" \"+ Labels[classIDs[i]]\n",
    "                detected.append(current_label)\n",
    "                \n",
    "                #print(\"out_text: \",out_text)\n",
    "\n",
    "                if(out_text not in detected_objects):\n",
    "                    t2=threading.Thread(target=playing_audio)\n",
    "                    t2.start()\n",
    "                    detected_objects.append(out_text)\n",
    "\n",
    "                current_text=out_text\n",
    "\n",
    "    return frame     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that take the frames from the camera and pass it\n",
    "# to the video_stream_with_objectDetection function\n",
    "# then display the modified frame in the output(\"webcam\") window \n",
    "def playing_video(cap):\n",
    "    global frame_count\n",
    "    ret, frame = cap.read()\n",
    "    #frame=cv2.flip(frame,1)\n",
    "    frame_count += 1\n",
    "    if ret:\n",
    "        cv2.imshow(\"Webcam\",video_stream_with_objectDetection(frame,frame_count)) \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR with Simple Chatbot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funciton to listen to the voice of the user through microphone\n",
    "# and convert it to a text\n",
    "# then return this text \n",
    "def listen(recognizer, microphone):\n",
    "    print(\"listing\")\n",
    "    try:\n",
    "        with microphone as source:\n",
    "            recognizer.adjust_for_ambient_noise(source)\n",
    "            recognizer.dynamic_energy_thereshold=1000\n",
    "            audio=recognizer.listen(source, timeout=2)\n",
    "            response=recognizer.recognize_google(audio)\n",
    "            print(response)\n",
    "            return response\n",
    "\n",
    "    except sr.WaitTimeoutError:\n",
    "        print(\"timeError\")\n",
    "        return \"\"\n",
    "\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"couldn't recognize\")\n",
    "        return \"\"\n",
    "\n",
    "    except sr.RequestError:\n",
    "        print(\"Network error\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that ask the user if he want to read from existing file\n",
    "# if yes: it will ask the user for the file name\n",
    "# then will check if the file exist\n",
    "# if yes: it will read the file\n",
    "# if no: it will say that the file doesn't exist, and ask the user again \n",
    "# for the correct file name\n",
    "def read_ocr_file():\n",
    "    isExist=False\n",
    "    file_name =\"\"\n",
    "    text=\"\"\n",
    "    recognizer =sr.Recognizer()\n",
    "    microphone =sr.Microphone()\n",
    "    engine=pyttsx3.init()\n",
    "    engine.say(\"Do You Want me to read from an existing file\")\n",
    "    engine.runAndWait()\n",
    "    while text==\"\":\n",
    "        text =listen(recognizer, microphone)\n",
    "\n",
    "    if text==\"yes\":    \n",
    "        while not isExist:\n",
    "            engine=pyttsx3.init()\n",
    "            engine.say(\"Please, say the name of the file\")\n",
    "            engine.runAndWait()\n",
    "            engine =None\n",
    "            while file_name==\"\":\n",
    "                file_name =listen(recognizer, microphone)\n",
    "            \n",
    "            isExist =os.path.exists(file_name)\n",
    "            if(isExist):\n",
    "                engine =pyttsx3.init()\n",
    "                with open(file_name) as f:\n",
    "                    for line in f:\n",
    "                        text +=line+\" \"\n",
    "                    #text_in_file =f.readlines()\n",
    "                engine.say(text)\n",
    "                engine.runAndWait()\n",
    "                engine =None\n",
    "\n",
    "                return True\n",
    "            else:\n",
    "                current_text=\"There is no file exist With the name\"+file_name\n",
    "                engine=pyttsx3.init()\n",
    "                engine.say(current_text)\n",
    "                engine.runAndWait()\n",
    "                engine =None\n",
    "                file_name=\"\"\n",
    "    elif(text==\"no\"):\n",
    "        return False\n",
    "    else:\n",
    "        return False    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to ask the user if he want to save the ocr_text to a file\n",
    "# if yes: then it will ask the user for the name of the file\n",
    "# then will save the current text to a file with the name taken\n",
    "# if other: it will not do anything\n",
    "def Save_ocr_file(ocr_output_text):    \n",
    "    file_name_verify=\"\"\n",
    "    file_name=\"\"\n",
    "    text=\"\"\n",
    "\n",
    "    recognizer =sr.Recognizer()\n",
    "    microphone =sr.Microphone()\n",
    "\n",
    "    engine=pyttsx3.init()\n",
    "    engine.say(\"Do You Want to save the current text To A file?\")\n",
    "    engine.runAndWait()\n",
    "    engine =None\n",
    "\n",
    "    while text ==\"\":\n",
    "        text =listen(recognizer, microphone)\n",
    "\n",
    "    if text ==\"yes\":\n",
    "\n",
    "        while (file_name_verify !=\"yes\"):\n",
    "            file_name_verify=\"\"\n",
    "            file_name=\"\"\n",
    "            engine=pyttsx3.init()\n",
    "            engine.say(\"Please Say the name of the file\")\n",
    "            engine.runAndWait()\n",
    "            engine =None\n",
    "\n",
    "            while file_name ==\"\":\n",
    "                file_name =listen(recognizer, microphone)  \n",
    "\n",
    "            current_text=\"is\"+file_name+\"the name of the new file?\"        \n",
    "            engine=pyttsx3.init()\n",
    "            engine.say(current_text)\n",
    "            engine.runAndWait()\n",
    "            engine =None\n",
    "\n",
    "            while file_name_verify ==\"\":\n",
    "                file_name_verify =listen(recognizer, microphone)\n",
    " \n",
    "        engine=pyttsx3.init()\n",
    "        engine.say(\"Saving the new file, Please Wait\")\n",
    "        engine.runAndWait()\n",
    "        engine =None\n",
    "\n",
    "        # writing ocr_text_output to the new file\n",
    "        with open(file_name, \"w\") as f:\n",
    "            f.write(ocr_output_text)\n",
    "\n",
    "\n",
    "        engine=pyttsx3.init()\n",
    "        engine.say(\"file is saved\")\n",
    "        engine.runAndWait()   \n",
    "        engine =None     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that use Ocr.Space to get the image and send it the api\n",
    "# throught an apiKey, then it take the responds and get the result text\n",
    "# from it\n",
    "# if the text is not empty: it will read it\n",
    "# then will call the Save_ocr_file function to check if the user want to \n",
    "# save the file or not\n",
    "# if the text is empty: it will tell the user that it couldn't scan the text\n",
    "def edited_ocr(img): \n",
    "    print(\"ocr_funciton\")\n",
    "    url_api=\"https://api.ocr.space/parse/image\"\n",
    "\n",
    "    img_gray =cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imwrite(filename=\"ocr_image.jpg\",img=img_gray)\n",
    "    file_img =cv2.imread(\"ocr_image.jpg\")\n",
    "    _, compressedImage=cv2.imencode(\".jpg\",file_img,[1,90])\n",
    "    file_bytes=io.BytesIO(compressedImage)\n",
    "\n",
    "    result = requests.post(url_api,\n",
    "              files = {\"ocr_image.jpg\": file_bytes},\n",
    "              data = {\"apikey\": \"K81364605688957\",\n",
    "                      \"language\": \"eng\"})\n",
    "    \n",
    "    result =result.content.decode()\n",
    "    result=json.loads(result)\n",
    "\n",
    "    text =result.get(\"ParsedResults\")[0].get(\"ParsedText\")\n",
    "    print(text)\n",
    "    if (text != \"\"):\n",
    "        engine=pyttsx3.init()\n",
    "        engine.say(text)\n",
    "        engine.runAndWait()\n",
    "        engine =None\n",
    "        Save_ocr_file(text)\n",
    "    else:\n",
    "        engine=pyttsx3.init()\n",
    "        engine.say(\"couldn't scan the text, pleas hold it the text in a clear way\")\n",
    "        engine.runAndWait()\n",
    "        engine =None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to display the ocr_window untill the user say the word (start)\n",
    "# then it will capture the image\n",
    "def display_ocr_window(cap):\n",
    "    global read_text\n",
    "    global ocr_start\n",
    "    global read_save_file\n",
    "    global read_saved_file_for_the_firstTime\n",
    "    ret, frame = cap.read()\n",
    "    #frame=cv2.flip(frame,1)\n",
    "    if ret:\n",
    "        cv2.imshow(\"OCR_Detection\",frame)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "        if(read_text)and(not read_save_file)and(ocr_start):       \n",
    "            edited_ocr(frame)\n",
    "            read_saved_file_for_the_firstTime=True\n",
    "            read_text=False \n",
    "            read_save_file=True   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions Setting: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to enable each function when the user say a specific word\n",
    "# 1-> start object_detection\n",
    "# 2-> start ocr window\n",
    "# start -> scan the text\n",
    "# exit -> exit the program\n",
    "# the funciton uses the listen function to listen to the user's voice\n",
    "# througth the microphone\n",
    "def set_function():  \n",
    "    global ocr_start\n",
    "    global read_text\n",
    "    global objectDetection_start\n",
    "    global exit_Program\n",
    "    global start_new_thread\n",
    "\n",
    "    start_new_thread=False\n",
    "    \n",
    "    recognizer =sr.Recognizer()\n",
    "    microphone =sr.Microphone()     \n",
    "    text =listen(recognizer, microphone)\n",
    "        \n",
    "    if(text ==\"1\"):  #\"start object detection\" \n",
    "        if(ocr_start):\n",
    "            ocr_start=False\n",
    "        objectDetection_start=True    \n",
    "        \n",
    "    elif(text ==\"scan\"): #\"start scanning the text\"\n",
    "        read_text=True\n",
    "\n",
    "    elif(text ==\"2\"): #\"start ocr\"\n",
    "        if(objectDetection_start):\n",
    "            objectDetection_start=False     \n",
    "        ocr_start=True\n",
    "        read_saved_file_for_the_firstTime=True\n",
    "     \n",
    "     \n",
    "    elif(text ==\"exit\"):\n",
    "        exit_Program=True\n",
    "\n",
    "    else:\n",
    "        print(\"else: \",text)\n",
    " \n",
    "    start_new_thread=True   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the main function where all other functions are organized in it\n",
    "text=\"\"\n",
    "audio_text=\"\"\n",
    "texts=[]\n",
    "current_text=\"\"\n",
    "out_text=\"\"\n",
    "detected_objects =[]\n",
    "\n",
    "exit_Program=False\n",
    "objectDetection_start=False\n",
    "ocr_start=False\n",
    "read_text=False\n",
    "start_new_thread=True\n",
    "\n",
    "read_saved_file_for_the_firstTime =True\n",
    "\n",
    "#\"E:\\\\AlaaFiles\\\\yolov7\\\\coco.yaml\"\n",
    "#\"E:\\\\AlaaFiles\\\\Amit_Gradution_Porject\\\\yolo.cfg\", \"E:\\\\AlaaFiles\\\\yolov7\\\\yolov7-tiny.weights\n",
    "\n",
    "\n",
    "Labels =open(\"coco.yaml\").read().strip().split('\\n')\n",
    "\n",
    "# initilalize a list of colors\n",
    "np.random.seed(42)\n",
    "COLORS =np.random.randint(0,255,size=(len(Labels),3),dtype=\"uint8\")\n",
    "\n",
    "# Weights_Path =\"yolov7-tiny.weights\" \n",
    "# Config_Path =\"yolo.cfg\"\n",
    "\n",
    "Weights_Path =\"yolov7-tiny.weights\"  \n",
    "Config_Path =\"yolov7.cfg\"\n",
    "\n",
    "# load nueral network from darknet #readNetFromDarknet\n",
    "network = cv2.dnn.readNetFromDarknet(Config_Path, Weights_Path)\n",
    "\n",
    "# get layer names\n",
    "layer_names =network.getLayerNames()\n",
    "\n",
    "# get unconnected layers(output_layer) names\n",
    "layer_names =[layer_names[i-1] for i in network.getUnconnectedOutLayers()]\n",
    " \n",
    "\n",
    "filewrite =open(\"ocr_text\",\"w\")\n",
    "\n",
    "frame_count = 0\n",
    "first = True\n",
    "frames = []\n",
    "started=True\n",
    "\n",
    "\n",
    "if __name__ ==\"__main__\":\n",
    "    engine =pyttsx3.init()\n",
    "    engine.say(\"Amit Graduation Project\")\n",
    "    engine.say(\"Alaa Mohamed Sayed Ibrahim\")\n",
    "    engine.say(\"For Object Detection Please Say one\")\n",
    "    engine.say(\"For reading Text Please Say Two\")\n",
    "    engine.say(\"to exit the program Please Say Exit\")\n",
    "    engine.runAndWait()\n",
    "    engine =None\n",
    "    start=False\n",
    "    set_function()\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    # cap.set(3,416)\n",
    "    # cap.set(4,416) \n",
    "    \n",
    "    now =time.time()\n",
    "\n",
    "    while(not exit_Program) :\n",
    "        if((start_new_thread)):  \n",
    "            t1=threading.Thread(target=set_function)\n",
    "            t1.start()    \n",
    "\n",
    "        if(objectDetection_start):\n",
    "            playing_video(cap)\n",
    "\n",
    "        elif(ocr_start):\n",
    "            if(read_saved_file_for_the_firstTime):\n",
    "                read_save_file =read_ocr_file()\n",
    "                read_saved_file_for_the_firstTime=False\n",
    "                print(\"in read function\")\n",
    "\n",
    "                \n",
    "                #if( read_save_file): #not\n",
    "                engine=pyttsx3.init()\n",
    "                engine.say(\"When You are ready, Please Say scan\")\n",
    "                engine.runAndWait()\n",
    "                engine =None\n",
    "\n",
    "            display_ocr_window(cap)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    " \n",
    "    print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "591b40349d00f0bd867c2193c288a38fd782376f854f9ffd594ef8dfb3641b80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
